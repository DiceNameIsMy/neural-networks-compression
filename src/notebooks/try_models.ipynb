{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a9bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(levelname)s: %(message)s\",\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(str(Path.cwd().parent.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7233f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading cached vertebral from /home/nur/Projects/vut-ip1-nn-quantization/datasets_cache/vertebral_cache.pkl\n"
     ]
    }
   ],
   "source": [
    "from src.datasets.vertebral_dataset import VertebralDataset\n",
    "\n",
    "from src.models.mlp import (\n",
    "    MLPEvaluator,\n",
    "    KFoldMLPEvaluator,\n",
    "    MLPParams,\n",
    "    FCParams,\n",
    "    FCLayerParams,\n",
    "    WeightQuantMode,\n",
    ")\n",
    "from src.models.nn import ActivationModule, ActivationParams, NNTrainParams\n",
    "from src.models.quant.enums import QMode\n",
    "\n",
    "DatasetClass = VertebralDataset\n",
    "train_loader, test_loader = DatasetClass.get_dataloaders(batch_size=32)\n",
    "\n",
    "train_params = NNTrainParams(\n",
    "    DatasetClass,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=15,\n",
    "    learning_rate=0.01,\n",
    "    weight_decay=0.0001,\n",
    "    early_stop_patience=10,\n",
    ")\n",
    "fc_params = FCParams(\n",
    "    layers=[\n",
    "        FCLayerParams(DatasetClass.input_size, WeightQuantMode.NBITS, 16),\n",
    "        FCLayerParams(32, WeightQuantMode.BINARY),\n",
    "        FCLayerParams(32, WeightQuantMode.BINARY),\n",
    "        FCLayerParams(DatasetClass.output_size, WeightQuantMode.BINARY),\n",
    "    ],\n",
    "    activation=ActivationParams(ActivationModule.BINARIZE_RESTE),\n",
    "    qmode=QMode.DET,\n",
    "    dropout_rate=0.0,\n",
    ")\n",
    "mlp_params = MLPParams(fc=fc_params, train=train_params)\n",
    "\n",
    "evaluator = MLPEvaluator(mlp_params)\n",
    "# evaluator.evaluate_model(times=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9044855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Train Epoch:  1 [  32/248] Loss: 1.1397\n",
      "DEBUG: Train Epoch:  1 [ 192/248] Loss: 0.9253\n",
      "DEBUG: Test set: Average loss: 0.7207, Accuracy: 39/62 (62.90%)\n",
      "DEBUG: Train Epoch:  2 [  32/248] Loss: 0.8617\n",
      "DEBUG: Train Epoch:  2 [ 192/248] Loss: 0.8314\n",
      "DEBUG: Test set: Average loss: 0.6054, Accuracy: 41/62 (66.13%)\n",
      "DEBUG: Train Epoch:  3 [  32/248] Loss: 0.9128\n",
      "DEBUG: Train Epoch:  3 [ 192/248] Loss: 0.8866\n",
      "DEBUG: Test set: Average loss: 0.5875, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch:  4 [  32/248] Loss: 0.8655\n",
      "DEBUG: Train Epoch:  4 [ 192/248] Loss: 0.8776\n",
      "DEBUG: Test set: Average loss: 0.5870, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch:  5 [  32/248] Loss: 0.8903\n",
      "DEBUG: Train Epoch:  5 [ 192/248] Loss: 0.8729\n",
      "DEBUG: Test set: Average loss: 0.5477, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch:  6 [  32/248] Loss: 0.8864\n",
      "DEBUG: Train Epoch:  6 [ 192/248] Loss: 0.8776\n",
      "DEBUG: Test set: Average loss: 0.5899, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch:  7 [  32/248] Loss: 0.8604\n",
      "DEBUG: Train Epoch:  7 [ 192/248] Loss: 0.8322\n",
      "DEBUG: Test set: Average loss: 0.6800, Accuracy: 41/62 (66.13%)\n",
      "DEBUG: Train Epoch:  8 [  32/248] Loss: 0.8226\n",
      "DEBUG: Train Epoch:  8 [ 192/248] Loss: 0.8249\n",
      "DEBUG: Test set: Average loss: 0.5851, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch:  9 [  32/248] Loss: 0.8338\n",
      "DEBUG: Train Epoch:  9 [ 192/248] Loss: 0.8263\n",
      "DEBUG: Test set: Average loss: 0.5118, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch: 10 [  32/248] Loss: 0.8600\n",
      "DEBUG: Train Epoch: 10 [ 192/248] Loss: 0.7875\n",
      "DEBUG: Test set: Average loss: 0.5540, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch: 11 [  32/248] Loss: 0.8478\n",
      "DEBUG: Train Epoch: 11 [ 192/248] Loss: 0.8412\n",
      "DEBUG: Test set: Average loss: 0.5713, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch: 12 [  32/248] Loss: 0.7948\n",
      "DEBUG: Train Epoch: 12 [ 192/248] Loss: 0.8087\n",
      "DEBUG: Test set: Average loss: 0.5069, Accuracy: 53/62 (85.48%)\n",
      "DEBUG: Train Epoch: 13 [  32/248] Loss: 0.8124\n",
      "DEBUG: Train Epoch: 13 [ 192/248] Loss: 0.8177\n",
      "DEBUG: Test set: Average loss: 0.5199, Accuracy: 46/62 (74.19%)\n",
      "DEBUG: Train Epoch: 14 [  32/248] Loss: 0.7948\n",
      "DEBUG: Train Epoch: 14 [ 192/248] Loss: 0.8602\n",
      "DEBUG: Test set: Average loss: 0.5048, Accuracy: 46/62 (74.19%)\n",
      "DEBUG: Train Epoch: 15 [  32/248] Loss: 0.8461\n",
      "DEBUG: Train Epoch: 15 [ 192/248] Loss: 0.8410\n",
      "DEBUG: Test set: Average loss: 0.4956, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Test set: Average loss: 0.4956, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch:  1 [  32/248] Loss: 1.1456\n",
      "DEBUG: Train Epoch:  1 [ 192/248] Loss: 0.8864\n",
      "DEBUG: Test set: Average loss: 0.7166, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch:  2 [  32/248] Loss: 0.8864\n",
      "DEBUG: Train Epoch:  2 [ 192/248] Loss: 0.9128\n",
      "DEBUG: Test set: Average loss: 0.6299, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch:  3 [  32/248] Loss: 0.9040\n",
      "DEBUG: Train Epoch:  3 [ 192/248] Loss: 0.9332\n",
      "DEBUG: Test set: Average loss: 0.6014, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch:  4 [  32/248] Loss: 0.8725\n",
      "DEBUG: Train Epoch:  4 [ 192/248] Loss: 0.8439\n",
      "DEBUG: Test set: Average loss: 0.5754, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch:  5 [  32/248] Loss: 0.8729\n",
      "DEBUG: Train Epoch:  5 [ 192/248] Loss: 0.8566\n",
      "DEBUG: Test set: Average loss: 0.6227, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch:  6 [  32/248] Loss: 0.8828\n",
      "DEBUG: Train Epoch:  6 [ 192/248] Loss: 0.8175\n",
      "DEBUG: Test set: Average loss: 0.6271, Accuracy: 43/62 (69.35%)\n",
      "DEBUG: Train Epoch:  7 [  32/248] Loss: 0.8476\n",
      "DEBUG: Train Epoch:  7 [ 192/248] Loss: 0.8212\n",
      "DEBUG: Test set: Average loss: 0.5187, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch:  8 [  32/248] Loss: 0.8513\n",
      "DEBUG: Train Epoch:  8 [ 192/248] Loss: 0.8549\n",
      "DEBUG: Test set: Average loss: 0.5700, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch:  9 [  32/248] Loss: 0.8674\n",
      "DEBUG: Train Epoch:  9 [ 192/248] Loss: 0.8212\n",
      "DEBUG: Test set: Average loss: 0.5935, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch: 10 [  32/248] Loss: 0.8300\n",
      "DEBUG: Train Epoch: 10 [ 192/248] Loss: 0.8425\n",
      "DEBUG: Test set: Average loss: 0.5277, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch: 11 [  32/248] Loss: 0.9064\n",
      "DEBUG: Train Epoch: 11 [ 192/248] Loss: 0.8425\n",
      "DEBUG: Test set: Average loss: 0.7496, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch: 12 [  32/248] Loss: 0.8212\n",
      "DEBUG: Train Epoch: 12 [ 192/248] Loss: 0.8514\n",
      "DEBUG: Test set: Average loss: 0.5813, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch: 13 [  32/248] Loss: 0.8410\n",
      "DEBUG: Train Epoch: 13 [ 192/248] Loss: 0.8300\n",
      "DEBUG: Test set: Average loss: 0.5611, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch: 14 [  32/248] Loss: 0.8263\n",
      "DEBUG: Train Epoch: 14 [ 192/248] Loss: 0.8854\n",
      "DEBUG: Test set: Average loss: 0.5487, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch: 15 [  32/248] Loss: 0.7862\n",
      "DEBUG: Train Epoch: 15 [ 192/248] Loss: 0.8637\n",
      "DEBUG: Test set: Average loss: 0.4923, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Test set: Average loss: 0.4923, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch:  1 [  32/248] Loss: 1.1885\n",
      "DEBUG: Train Epoch:  1 [ 192/248] Loss: 0.8314\n",
      "DEBUG: Test set: Average loss: 1.0012, Accuracy: 32/62 (51.61%)\n",
      "DEBUG: Train Epoch:  2 [  32/248] Loss: 0.8828\n",
      "DEBUG: Train Epoch:  2 [ 192/248] Loss: 0.8743\n",
      "DEBUG: Test set: Average loss: 0.8900, Accuracy: 30/62 (48.39%)\n",
      "DEBUG: Train Epoch:  3 [  32/248] Loss: 0.9042\n",
      "DEBUG: Train Epoch:  3 [ 192/248] Loss: 0.8476\n",
      "DEBUG: Test set: Average loss: 0.8054, Accuracy: 25/62 (40.32%)\n",
      "DEBUG: Train Epoch:  4 [  32/248] Loss: 0.8641\n",
      "DEBUG: Train Epoch:  4 [ 192/248] Loss: 0.7911\n",
      "DEBUG: Test set: Average loss: 1.0651, Accuracy: 27/62 (43.55%)\n",
      "DEBUG: Train Epoch:  5 [  32/248] Loss: 0.8263\n",
      "DEBUG: Train Epoch:  5 [ 192/248] Loss: 0.8351\n",
      "DEBUG: Test set: Average loss: 1.0497, Accuracy: 32/62 (51.61%)\n",
      "DEBUG: Train Epoch:  6 [  32/248] Loss: 0.7911\n",
      "DEBUG: Train Epoch:  6 [ 192/248] Loss: 0.8441\n",
      "DEBUG: Test set: Average loss: 0.8269, Accuracy: 37/62 (59.68%)\n",
      "DEBUG: Train Epoch:  7 [  32/248] Loss: 0.7999\n",
      "DEBUG: Train Epoch:  7 [ 192/248] Loss: 0.8600\n",
      "DEBUG: Test set: Average loss: 0.9323, Accuracy: 32/62 (51.61%)\n",
      "DEBUG: Train Epoch:  8 [  32/248] Loss: 0.8514\n",
      "DEBUG: Train Epoch:  8 [ 192/248] Loss: 0.8742\n",
      "DEBUG: Test set: Average loss: 0.7211, Accuracy: 36/62 (58.06%)\n",
      "DEBUG: Train Epoch:  9 [  32/248] Loss: 0.8314\n",
      "DEBUG: Train Epoch:  9 [ 192/248] Loss: 0.8439\n",
      "DEBUG: Test set: Average loss: 0.9203, Accuracy: 38/62 (61.29%)\n",
      "DEBUG: Train Epoch: 10 [  32/248] Loss: 0.8463\n",
      "DEBUG: Train Epoch: 10 [ 192/248] Loss: 0.8461\n",
      "DEBUG: Test set: Average loss: 0.7483, Accuracy: 39/62 (62.90%)\n",
      "DEBUG: Train Epoch: 11 [  32/248] Loss: 0.8388\n",
      "DEBUG: Train Epoch: 11 [ 192/248] Loss: 0.8337\n",
      "DEBUG: Test set: Average loss: 0.7567, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch: 12 [  32/248] Loss: 0.8476\n",
      "DEBUG: Train Epoch: 12 [ 192/248] Loss: 0.8214\n",
      "DEBUG: Test set: Average loss: 0.7825, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch: 13 [  32/248] Loss: 0.8551\n",
      "DEBUG: Train Epoch: 13 [ 192/248] Loss: 0.8690\n",
      "DEBUG: Test set: Average loss: 0.7973, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch: 14 [  32/248] Loss: 0.8163\n",
      "DEBUG: Train Epoch: 14 [ 192/248] Loss: 0.8678\n",
      "DEBUG: Test set: Average loss: 0.9692, Accuracy: 33/62 (53.23%)\n",
      "DEBUG: Train Epoch: 15 [  32/248] Loss: 0.8089\n",
      "DEBUG: Train Epoch: 15 [ 192/248] Loss: 0.8050\n",
      "DEBUG: Test set: Average loss: 1.2561, Accuracy: 30/62 (48.39%)\n",
      "DEBUG: Test set: Average loss: 1.2561, Accuracy: 30/62 (48.39%)\n",
      "DEBUG: Train Epoch:  1 [  32/248] Loss: 1.1196\n",
      "DEBUG: Train Epoch:  1 [ 192/248] Loss: 0.8578\n",
      "DEBUG: Test set: Average loss: 1.0542, Accuracy: 30/62 (48.39%)\n",
      "DEBUG: Train Epoch:  2 [  32/248] Loss: 0.8703\n",
      "DEBUG: Train Epoch:  2 [ 192/248] Loss: 0.8828\n",
      "DEBUG: Test set: Average loss: 0.9700, Accuracy: 33/62 (53.23%)\n",
      "DEBUG: Train Epoch:  3 [  32/248] Loss: 0.9081\n",
      "DEBUG: Train Epoch:  3 [ 192/248] Loss: 0.8903\n",
      "DEBUG: Test set: Average loss: 1.0496, Accuracy: 35/62 (56.45%)\n",
      "DEBUG: Train Epoch:  4 [  32/248] Loss: 0.8602\n",
      "DEBUG: Train Epoch:  4 [ 192/248] Loss: 0.8439\n",
      "DEBUG: Test set: Average loss: 1.1973, Accuracy: 29/62 (46.77%)\n",
      "DEBUG: Train Epoch:  5 [  32/248] Loss: 0.8226\n",
      "DEBUG: Train Epoch:  5 [ 192/248] Loss: 0.8688\n",
      "DEBUG: Test set: Average loss: 1.1297, Accuracy: 30/62 (48.39%)\n",
      "DEBUG: Train Epoch:  6 [  32/248] Loss: 0.8351\n",
      "DEBUG: Train Epoch:  6 [ 192/248] Loss: 0.8351\n",
      "DEBUG: Test set: Average loss: 1.0955, Accuracy: 36/62 (58.06%)\n",
      "DEBUG: Train Epoch:  7 [  32/248] Loss: 0.8463\n",
      "DEBUG: Train Epoch:  7 [ 192/248] Loss: 0.8388\n",
      "DEBUG: Test set: Average loss: 1.6251, Accuracy: 13/62 (20.97%)\n",
      "DEBUG: Train Epoch:  8 [  32/248] Loss: 0.8351\n",
      "DEBUG: Train Epoch:  8 [ 192/248] Loss: 0.8087\n",
      "DEBUG: Test set: Average loss: 1.2093, Accuracy: 30/62 (48.39%)\n",
      "DEBUG: Train Epoch:  9 [  32/248] Loss: 0.8263\n",
      "DEBUG: Train Epoch:  9 [ 192/248] Loss: 0.8478\n",
      "DEBUG: Test set: Average loss: 1.0042, Accuracy: 33/62 (53.23%)\n",
      "DEBUG: Train Epoch: 10 [  32/248] Loss: 0.8300\n",
      "DEBUG: Train Epoch: 10 [ 192/248] Loss: 0.8087\n",
      "DEBUG: Test set: Average loss: 0.9451, Accuracy: 36/62 (58.06%)\n",
      "DEBUG: Train Epoch: 11 [  32/248] Loss: 0.7787\n",
      "DEBUG: Train Epoch: 11 [ 192/248] Loss: 0.8138\n",
      "DEBUG: Test set: Average loss: 0.9847, Accuracy: 35/62 (56.45%)\n",
      "DEBUG: Train Epoch: 12 [  32/248] Loss: 0.8901\n",
      "DEBUG: Train Epoch: 12 [ 192/248] Loss: 0.8776\n",
      "DEBUG: Test set: Average loss: 1.0026, Accuracy: 31/62 (50.00%)\n",
      "DEBUG: Train Epoch: 13 [  32/248] Loss: 0.8251\n",
      "DEBUG: Train Epoch: 13 [ 192/248] Loss: 0.8776\n",
      "DEBUG: Test set: Average loss: 1.0157, Accuracy: 29/62 (46.77%)\n",
      "DEBUG: Train Epoch: 14 [  32/248] Loss: 0.8943\n",
      "DEBUG: Train Epoch: 14 [ 192/248] Loss: 0.8124\n",
      "DEBUG: Test set: Average loss: 0.9594, Accuracy: 36/62 (58.06%)\n",
      "DEBUG: Train Epoch: 15 [  32/248] Loss: 0.8087\n",
      "DEBUG: Train Epoch: 15 [ 192/248] Loss: 0.8126\n",
      "DEBUG: Test set: Average loss: 1.1388, Accuracy: 26/62 (41.94%)\n",
      "DEBUG: Test set: Average loss: 1.1388, Accuracy: 26/62 (41.94%)\n",
      "DEBUG: Train Epoch:  1 [  32/248] Loss: 1.2163\n",
      "DEBUG: Train Epoch:  1 [ 192/248] Loss: 0.9547\n",
      "DEBUG: Test set: Average loss: 0.8428, Accuracy: 35/62 (56.45%)\n",
      "DEBUG: Train Epoch:  2 [  32/248] Loss: 0.9316\n",
      "DEBUG: Train Epoch:  2 [ 192/248] Loss: 0.8828\n",
      "DEBUG: Test set: Average loss: 0.6327, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch:  3 [  32/248] Loss: 0.8916\n",
      "DEBUG: Train Epoch:  3 [ 192/248] Loss: 0.8817\n",
      "DEBUG: Test set: Average loss: 0.5350, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch:  4 [  32/248] Loss: 0.9114\n",
      "DEBUG: Train Epoch:  4 [ 192/248] Loss: 0.8652\n",
      "DEBUG: Test set: Average loss: 0.5647, Accuracy: 43/62 (69.35%)\n",
      "DEBUG: Train Epoch:  5 [  32/248] Loss: 0.8654\n",
      "DEBUG: Train Epoch:  5 [ 192/248] Loss: 0.8600\n",
      "DEBUG: Test set: Average loss: 0.6159, Accuracy: 40/62 (64.52%)\n",
      "DEBUG: Train Epoch:  6 [  32/248] Loss: 0.8690\n",
      "DEBUG: Train Epoch:  6 [ 192/248] Loss: 0.8263\n",
      "DEBUG: Test set: Average loss: 0.5371, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch:  7 [  32/248] Loss: 0.8300\n",
      "DEBUG: Train Epoch:  7 [ 192/248] Loss: 0.8952\n",
      "DEBUG: Test set: Average loss: 0.5288, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch:  8 [  32/248] Loss: 0.8263\n",
      "DEBUG: Train Epoch:  8 [ 192/248] Loss: 0.8036\n",
      "DEBUG: Test set: Average loss: 0.6700, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch:  9 [  32/248] Loss: 0.9116\n",
      "DEBUG: Train Epoch:  9 [ 192/248] Loss: 0.8740\n",
      "DEBUG: Test set: Average loss: 0.5318, Accuracy: 46/62 (74.19%)\n",
      "DEBUG: Train Epoch: 10 [  32/248] Loss: 0.8138\n",
      "DEBUG: Train Epoch: 10 [ 192/248] Loss: 0.8300\n",
      "DEBUG: Test set: Average loss: 0.5159, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch: 11 [  32/248] Loss: 0.8866\n",
      "DEBUG: Train Epoch: 11 [ 192/248] Loss: 0.8175\n",
      "DEBUG: Test set: Average loss: 0.5924, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch: 12 [  32/248] Loss: 0.7911\n",
      "DEBUG: Train Epoch: 12 [ 192/248] Loss: 0.8461\n",
      "DEBUG: Test set: Average loss: 0.5683, Accuracy: 52/62 (83.87%)\n",
      "DEBUG: Train Epoch: 13 [  32/248] Loss: 0.7911\n",
      "DEBUG: Train Epoch: 13 [ 192/248] Loss: 0.8502\n",
      "DEBUG: Test set: Average loss: 0.4289, Accuracy: 57/62 (91.94%)\n",
      "DEBUG: Train Epoch: 14 [  32/248] Loss: 0.7897\n",
      "DEBUG: Train Epoch: 14 [ 192/248] Loss: 0.8337\n",
      "DEBUG: Test set: Average loss: 0.4619, Accuracy: 51/62 (82.26%)\n",
      "DEBUG: Train Epoch: 15 [  32/248] Loss: 0.8373\n",
      "DEBUG: Train Epoch: 15 [ 192/248] Loss: 0.8226\n",
      "DEBUG: Test set: Average loss: 0.4815, Accuracy: 53/62 (85.48%)\n",
      "DEBUG: Test set: Average loss: 0.4815, Accuracy: 53/62 (85.48%)\n",
      "DEBUG: Train Epoch:  1 [  32/248] Loss: 1.1670\n",
      "DEBUG: Train Epoch:  1 [ 192/248] Loss: 0.9754\n",
      "DEBUG: Test set: Average loss: 0.8809, Accuracy: 37/62 (59.68%)\n",
      "DEBUG: Train Epoch:  2 [  32/248] Loss: 0.9283\n",
      "DEBUG: Train Epoch:  2 [ 192/248] Loss: 0.9204\n",
      "DEBUG: Test set: Average loss: 0.6551, Accuracy: 39/62 (62.90%)\n",
      "DEBUG: Train Epoch:  3 [  32/248] Loss: 0.8829\n",
      "DEBUG: Train Epoch:  3 [ 192/248] Loss: 0.8652\n",
      "DEBUG: Test set: Average loss: 0.6519, Accuracy: 40/62 (64.52%)\n",
      "DEBUG: Train Epoch:  4 [  32/248] Loss: 0.8954\n",
      "DEBUG: Train Epoch:  4 [ 192/248] Loss: 0.8866\n",
      "DEBUG: Test set: Average loss: 0.6749, Accuracy: 38/62 (61.29%)\n",
      "DEBUG: Train Epoch:  5 [  32/248] Loss: 0.8529\n",
      "DEBUG: Train Epoch:  5 [ 192/248] Loss: 0.8705\n",
      "DEBUG: Test set: Average loss: 0.5766, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch:  6 [  32/248] Loss: 0.8989\n",
      "DEBUG: Train Epoch:  6 [ 192/248] Loss: 0.8601\n",
      "DEBUG: Test set: Average loss: 0.7419, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch:  7 [  32/248] Loss: 0.8819\n",
      "DEBUG: Train Epoch:  7 [ 192/248] Loss: 0.9202\n",
      "DEBUG: Test set: Average loss: 0.6272, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch:  8 [  32/248] Loss: 0.8226\n",
      "DEBUG: Train Epoch:  8 [ 192/248] Loss: 0.8516\n",
      "DEBUG: Test set: Average loss: 0.5709, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch:  9 [  32/248] Loss: 0.8729\n",
      "DEBUG: Train Epoch:  9 [ 192/248] Loss: 0.8439\n",
      "DEBUG: Test set: Average loss: 0.5854, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch: 10 [  32/248] Loss: 0.8302\n",
      "DEBUG: Train Epoch: 10 [ 192/248] Loss: 0.8124\n",
      "DEBUG: Test set: Average loss: 0.5401, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch: 11 [  32/248] Loss: 0.8340\n",
      "DEBUG: Train Epoch: 11 [ 192/248] Loss: 0.8087\n",
      "DEBUG: Test set: Average loss: 0.5574, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch: 12 [  32/248] Loss: 0.8263\n",
      "DEBUG: Train Epoch: 12 [ 192/248] Loss: 0.8637\n",
      "DEBUG: Test set: Average loss: 0.5327, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch: 13 [  32/248] Loss: 0.7647\n",
      "DEBUG: Train Epoch: 13 [ 192/248] Loss: 0.8776\n",
      "DEBUG: Test set: Average loss: 0.4506, Accuracy: 51/62 (82.26%)\n",
      "DEBUG: Train Epoch: 14 [  32/248] Loss: 0.8226\n",
      "DEBUG: Train Epoch: 14 [ 192/248] Loss: 0.7647\n",
      "DEBUG: Test set: Average loss: 0.7641, Accuracy: 43/62 (69.35%)\n",
      "DEBUG: Train Epoch: 15 [  32/248] Loss: 0.7948\n",
      "DEBUG: Train Epoch: 15 [ 192/248] Loss: 0.7823\n",
      "DEBUG: Test set: Average loss: 0.6012, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Test set: Average loss: 0.6012, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch:  1 [  32/248] Loss: 1.2970\n",
      "DEBUG: Train Epoch:  1 [ 192/248] Loss: 0.8828\n",
      "DEBUG: Test set: Average loss: 1.2673, Accuracy: 33/62 (53.23%)\n",
      "DEBUG: Train Epoch:  2 [  32/248] Loss: 0.8903\n",
      "DEBUG: Train Epoch:  2 [ 192/248] Loss: 0.8829\n",
      "DEBUG: Test set: Average loss: 0.6876, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch:  3 [  32/248] Loss: 0.8527\n",
      "DEBUG: Train Epoch:  3 [ 192/248] Loss: 0.8463\n",
      "DEBUG: Test set: Average loss: 0.5241, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch:  4 [  32/248] Loss: 0.8615\n",
      "DEBUG: Train Epoch:  4 [ 192/248] Loss: 0.8527\n",
      "DEBUG: Test set: Average loss: 0.5905, Accuracy: 41/62 (66.13%)\n",
      "DEBUG: Train Epoch:  5 [  32/248] Loss: 0.8655\n",
      "DEBUG: Train Epoch:  5 [ 192/248] Loss: 0.8776\n",
      "DEBUG: Test set: Average loss: 0.5812, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch:  6 [  32/248] Loss: 0.8175\n",
      "DEBUG: Train Epoch:  6 [ 192/248] Loss: 0.8439\n",
      "DEBUG: Test set: Average loss: 0.4626, Accuracy: 52/62 (83.87%)\n",
      "DEBUG: Train Epoch:  7 [  32/248] Loss: 0.7875\n",
      "DEBUG: Train Epoch:  7 [ 192/248] Loss: 0.8864\n",
      "DEBUG: Test set: Average loss: 0.4740, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch:  8 [  32/248] Loss: 0.8314\n",
      "DEBUG: Train Epoch:  8 [ 192/248] Loss: 0.8688\n",
      "DEBUG: Test set: Average loss: 0.4827, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch:  9 [  32/248] Loss: 0.8527\n",
      "DEBUG: Train Epoch:  9 [ 192/248] Loss: 0.8087\n",
      "DEBUG: Test set: Average loss: 0.6006, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch: 10 [  32/248] Loss: 0.8813\n",
      "DEBUG: Train Epoch: 10 [ 192/248] Loss: 0.7963\n",
      "DEBUG: Test set: Average loss: 0.5074, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch: 11 [  32/248] Loss: 0.8337\n",
      "DEBUG: Train Epoch: 11 [ 192/248] Loss: 0.8439\n",
      "DEBUG: Test set: Average loss: 0.4799, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch: 12 [  32/248] Loss: 0.8263\n",
      "DEBUG: Train Epoch: 12 [ 192/248] Loss: 0.9052\n",
      "DEBUG: Test set: Average loss: 0.4904, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch: 13 [  32/248] Loss: 0.8690\n",
      "DEBUG: Train Epoch: 13 [ 192/248] Loss: 0.8126\n",
      "DEBUG: Test set: Average loss: 0.5077, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch: 14 [  32/248] Loss: 0.7825\n",
      "DEBUG: Train Epoch: 14 [ 192/248] Loss: 0.9475\n",
      "DEBUG: Test set: Average loss: 0.5388, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch: 15 [  32/248] Loss: 0.8711\n",
      "DEBUG: Train Epoch: 15 [ 192/248] Loss: 0.8214\n",
      "DEBUG: Test set: Average loss: 0.6273, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Test set: Average loss: 0.6273, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch:  1 [  32/248] Loss: 1.1841\n",
      "DEBUG: Train Epoch:  1 [ 192/248] Loss: 0.8652\n",
      "DEBUG: Test set: Average loss: 0.9195, Accuracy: 41/62 (66.13%)\n",
      "DEBUG: Train Epoch:  2 [  32/248] Loss: 0.9116\n",
      "DEBUG: Train Epoch:  2 [ 192/248] Loss: 0.8780\n",
      "DEBUG: Test set: Average loss: 0.6866, Accuracy: 41/62 (66.13%)\n",
      "DEBUG: Train Epoch:  3 [  32/248] Loss: 0.9209\n",
      "DEBUG: Train Epoch:  3 [ 192/248] Loss: 0.8514\n",
      "DEBUG: Test set: Average loss: 0.5167, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch:  4 [  32/248] Loss: 0.8402\n",
      "DEBUG: Train Epoch:  4 [ 192/248] Loss: 0.8952\n",
      "DEBUG: Test set: Average loss: 0.5674, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch:  5 [  32/248] Loss: 0.8868\n",
      "DEBUG: Train Epoch:  5 [ 192/248] Loss: 0.8828\n",
      "DEBUG: Test set: Average loss: 0.4862, Accuracy: 54/62 (87.10%)\n",
      "DEBUG: Train Epoch:  6 [  32/248] Loss: 0.8527\n",
      "DEBUG: Train Epoch:  6 [ 192/248] Loss: 0.8600\n",
      "DEBUG: Test set: Average loss: 0.5386, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch:  7 [  32/248] Loss: 0.8351\n",
      "DEBUG: Train Epoch:  7 [ 192/248] Loss: 0.8351\n",
      "DEBUG: Test set: Average loss: 0.5139, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch:  8 [  32/248] Loss: 0.8351\n",
      "DEBUG: Train Epoch:  8 [ 192/248] Loss: 0.8527\n",
      "DEBUG: Test set: Average loss: 0.5473, Accuracy: 46/62 (74.19%)\n",
      "DEBUG: Train Epoch:  9 [  32/248] Loss: 0.8782\n",
      "DEBUG: Train Epoch:  9 [ 192/248] Loss: 0.8050\n",
      "DEBUG: Test set: Average loss: 0.6434, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch: 10 [  32/248] Loss: 0.8439\n",
      "DEBUG: Train Epoch: 10 [ 192/248] Loss: 0.8439\n",
      "DEBUG: Test set: Average loss: 0.5677, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch: 11 [  32/248] Loss: 0.8527\n",
      "DEBUG: Train Epoch: 11 [ 192/248] Loss: 0.8527\n",
      "DEBUG: Test set: Average loss: 0.5379, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch: 12 [  32/248] Loss: 0.8688\n",
      "DEBUG: Train Epoch: 12 [ 192/248] Loss: 0.9613\n",
      "DEBUG: Test set: Average loss: 0.6565, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch: 13 [  32/248] Loss: 0.8373\n",
      "DEBUG: Train Epoch: 13 [ 192/248] Loss: 0.8639\n",
      "DEBUG: Test set: Average loss: 0.5908, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch: 14 [  32/248] Loss: 0.8564\n",
      "DEBUG: Train Epoch: 14 [ 192/248] Loss: 0.8087\n",
      "DEBUG: Test set: Average loss: 0.9847, Accuracy: 39/62 (62.90%)\n",
      "DEBUG: Train Epoch: 15 [  32/248] Loss: 0.8087\n",
      "DEBUG: Train Epoch: 15 [ 192/248] Loss: 0.8234\n",
      "DEBUG: Test set: Average loss: 0.6916, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Test set: Average loss: 0.6916, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch:  1 [  32/248] Loss: 1.0675\n",
      "DEBUG: Train Epoch:  1 [ 192/248] Loss: 0.9453\n",
      "DEBUG: Test set: Average loss: 0.7742, Accuracy: 35/62 (56.45%)\n",
      "DEBUG: Train Epoch:  2 [  32/248] Loss: 0.8617\n",
      "DEBUG: Train Epoch:  2 [ 192/248] Loss: 0.8919\n",
      "DEBUG: Test set: Average loss: 0.5962, Accuracy: 41/62 (66.13%)\n",
      "DEBUG: Train Epoch:  3 [  32/248] Loss: 0.8828\n",
      "DEBUG: Train Epoch:  3 [ 192/248] Loss: 0.8996\n",
      "DEBUG: Test set: Average loss: 0.5937, Accuracy: 43/62 (69.35%)\n",
      "DEBUG: Train Epoch:  4 [  32/248] Loss: 0.8705\n",
      "DEBUG: Train Epoch:  4 [ 192/248] Loss: 0.8916\n",
      "DEBUG: Test set: Average loss: 0.5930, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch:  5 [  32/248] Loss: 0.8527\n",
      "DEBUG: Train Epoch:  5 [ 192/248] Loss: 0.9378\n",
      "DEBUG: Test set: Average loss: 0.5879, Accuracy: 42/62 (67.74%)\n",
      "DEBUG: Train Epoch:  6 [  32/248] Loss: 0.8954\n",
      "DEBUG: Train Epoch:  6 [ 192/248] Loss: 0.8637\n",
      "DEBUG: Test set: Average loss: 0.5556, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch:  7 [  32/248] Loss: 0.8954\n",
      "DEBUG: Train Epoch:  7 [ 192/248] Loss: 0.8478\n",
      "DEBUG: Test set: Average loss: 0.5731, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch:  8 [  32/248] Loss: 0.8527\n",
      "DEBUG: Train Epoch:  8 [ 192/248] Loss: 0.8441\n",
      "DEBUG: Test set: Average loss: 0.5893, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch:  9 [  32/248] Loss: 0.8265\n",
      "DEBUG: Train Epoch:  9 [ 192/248] Loss: 0.8353\n",
      "DEBUG: Test set: Average loss: 0.5035, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch: 10 [  32/248] Loss: 0.8138\n",
      "DEBUG: Train Epoch: 10 [ 192/248] Loss: 0.8690\n",
      "DEBUG: Test set: Average loss: 0.5661, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch: 11 [  32/248] Loss: 0.8390\n",
      "DEBUG: Train Epoch: 11 [ 192/248] Loss: 0.8602\n",
      "DEBUG: Test set: Average loss: 0.5407, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch: 12 [  32/248] Loss: 0.8513\n",
      "DEBUG: Train Epoch: 12 [ 192/248] Loss: 0.8212\n",
      "DEBUG: Test set: Average loss: 0.5171, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch: 13 [  32/248] Loss: 0.8674\n",
      "DEBUG: Train Epoch: 13 [ 192/248] Loss: 0.8300\n",
      "DEBUG: Test set: Average loss: 0.5099, Accuracy: 50/62 (80.65%)\n",
      "DEBUG: Train Epoch: 14 [  32/248] Loss: 0.8087\n",
      "DEBUG: Train Epoch: 14 [ 192/248] Loss: 0.8263\n",
      "DEBUG: Test set: Average loss: 0.4870, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch: 15 [  32/248] Loss: 0.8337\n",
      "DEBUG: Train Epoch: 15 [ 192/248] Loss: 0.8888\n",
      "DEBUG: Test set: Average loss: 0.5644, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Test set: Average loss: 0.5644, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch:  1 [  32/248] Loss: 1.1044\n",
      "DEBUG: Train Epoch:  1 [ 192/248] Loss: 0.9442\n",
      "DEBUG: Test set: Average loss: 0.8819, Accuracy: 34/62 (54.84%)\n",
      "DEBUG: Train Epoch:  2 [  32/248] Loss: 0.9063\n",
      "DEBUG: Train Epoch:  2 [ 192/248] Loss: 0.9128\n",
      "DEBUG: Test set: Average loss: 0.5482, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch:  3 [  32/248] Loss: 0.9004\n",
      "DEBUG: Train Epoch:  3 [ 192/248] Loss: 0.8402\n",
      "DEBUG: Test set: Average loss: 0.5367, Accuracy: 46/62 (74.19%)\n",
      "DEBUG: Train Epoch:  4 [  32/248] Loss: 0.8829\n",
      "DEBUG: Train Epoch:  4 [ 192/248] Loss: 0.8654\n",
      "DEBUG: Test set: Average loss: 0.4968, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch:  5 [  32/248] Loss: 0.8529\n",
      "DEBUG: Train Epoch:  5 [ 192/248] Loss: 0.8791\n",
      "DEBUG: Test set: Average loss: 0.5275, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch:  6 [  32/248] Loss: 0.8226\n",
      "DEBUG: Train Epoch:  6 [ 192/248] Loss: 0.9119\n",
      "DEBUG: Test set: Average loss: 0.5242, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch:  7 [  32/248] Loss: 0.8740\n",
      "DEBUG: Train Epoch:  7 [ 192/248] Loss: 0.8439\n",
      "DEBUG: Test set: Average loss: 0.4859, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch:  8 [  32/248] Loss: 0.8529\n",
      "DEBUG: Train Epoch:  8 [ 192/248] Loss: 0.8226\n",
      "DEBUG: Test set: Average loss: 0.4940, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch:  9 [  32/248] Loss: 0.8490\n",
      "DEBUG: Train Epoch:  9 [ 192/248] Loss: 0.8703\n",
      "DEBUG: Test set: Average loss: 0.5074, Accuracy: 47/62 (75.81%)\n",
      "DEBUG: Train Epoch: 10 [  32/248] Loss: 0.8901\n",
      "DEBUG: Train Epoch: 10 [ 192/248] Loss: 0.8175\n",
      "DEBUG: Test set: Average loss: 0.4737, Accuracy: 48/62 (77.42%)\n",
      "DEBUG: Train Epoch: 11 [  32/248] Loss: 0.8476\n",
      "DEBUG: Train Epoch: 11 [ 192/248] Loss: 0.8300\n",
      "DEBUG: Test set: Average loss: 0.5824, Accuracy: 45/62 (72.58%)\n",
      "DEBUG: Train Epoch: 12 [  32/248] Loss: 0.8388\n",
      "DEBUG: Train Epoch: 12 [ 192/248] Loss: 0.8637\n",
      "DEBUG: Test set: Average loss: 0.5401, Accuracy: 49/62 (79.03%)\n",
      "DEBUG: Train Epoch: 13 [  32/248] Loss: 0.8263\n",
      "DEBUG: Train Epoch: 13 [ 192/248] Loss: 0.8476\n",
      "DEBUG: Test set: Average loss: 0.6175, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch: 14 [  32/248] Loss: 0.8776\n",
      "DEBUG: Train Epoch: 14 [ 192/248] Loss: 0.8625\n",
      "DEBUG: Test set: Average loss: 0.5793, Accuracy: 44/62 (70.97%)\n",
      "DEBUG: Train Epoch: 15 [  32/248] Loss: 0.8175\n",
      "DEBUG: Train Epoch: 15 [ 192/248] Loss: 0.8989\n",
      "DEBUG: Test set: Average loss: 0.6318, Accuracy: 41/62 (66.13%)\n",
      "DEBUG: Test set: Average loss: 0.6318, Accuracy: 41/62 (66.13%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max': 85.48387096774194,\n",
       " 'mean': np.float64(69.83870967741936),\n",
       " 'std': np.float64(13.359863477341174),\n",
       " 'accuracies': [75.80645161290323,\n",
       "  80.64516129032258,\n",
       "  48.38709677419355,\n",
       "  41.935483870967744,\n",
       "  85.48387096774194,\n",
       "  75.80645161290323,\n",
       "  79.03225806451613,\n",
       "  72.58064516129032,\n",
       "  72.58064516129032,\n",
       "  66.12903225806451]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KFoldMLPEvaluator(mlp_params).evaluate_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202de895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nur/Projects/vut-ip1-nn-quantization/src/datasets/dataset.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n",
      "/home/nur/Projects/vut-ip1-nn-quantization/src/datasets/dataset.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from src.constants import DEVICE\n",
    "from src.datasets.mnist_dataset import MiniMNISTDataset\n",
    "from src.models.cnn import CNN, CNNParams, ConvLayerParams, ConvParams\n",
    "\n",
    "CNNDatasetClass = MiniMNISTDataset\n",
    "cnn_train_loader, cnn_test_loader = CNNDatasetClass.get_dataloaders()\n",
    "\n",
    "conv_params = ConvParams(\n",
    "    in_channels=CNNDatasetClass.input_channels,\n",
    "    in_dimensions=CNNDatasetClass.input_dimensions,\n",
    "    in_bitwidth=8,\n",
    "    out_height=CNNDatasetClass.output_size,\n",
    "    layers=[\n",
    "        ConvLayerParams(channels=16, kernel_size=3, stride=1, padding=1),\n",
    "        ConvLayerParams(channels=32, kernel_size=3, stride=1, padding=1, pooling_kernel_size=2),\n",
    "    ],\n",
    "    activation=ActivationModule.BINARIZE,\n",
    "    qmode=QMode.DET,\n",
    "    reste_o=3,\n",
    "    reste_threshold=1.5,\n",
    "    dropout_rate=0.1,\n",
    ")\n",
    "cnn_fc_params = FCParams(\n",
    "    layers=[\n",
    "        FCLayerParams(-1, WeightQuantMode.NBITS, 16),\n",
    "        FCLayerParams(32, WeightQuantMode.BINARY),\n",
    "        FCLayerParams(32, WeightQuantMode.BINARY),\n",
    "        FCLayerParams(CNNDatasetClass.output_size, WeightQuantMode.BINARY),\n",
    "    ],\n",
    "    activation=ActivationParams(ActivationModule.BINARIZE_RESTE),\n",
    "    qmode=QMode.DET,\n",
    "    dropout_rate=0.0,\n",
    ")\n",
    "cnn_train_params = NNTrainParams(\n",
    "    CNNDatasetClass,\n",
    "    cnn_train_loader,\n",
    "    cnn_test_loader,\n",
    "    epochs=1,\n",
    "    learning_rate=0.01,\n",
    "    weight_decay=0.0001,\n",
    "    early_stop_patience=10,\n",
    ")\n",
    "cnn_params = CNNParams(\n",
    "    in_bitwidth=8,\n",
    "    conv=conv_params,\n",
    "    fc=cnn_fc_params,\n",
    "    train=cnn_train_params,\n",
    ")\n",
    "cnn = CNN(cnn_params).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a9c71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1504,  0.1504, -0.1504],\n",
       "         [ 0.1504, -0.1504, -0.1504],\n",
       "         [-0.1504, -0.1504, -0.1504]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.conv_layers[0][0].weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e851a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.nn import save_model\n",
    "\n",
    "\n",
    "save_model(cnn, \"cnn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380ad340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.nn import load_model\n",
    "\n",
    "\n",
    "cnn2 = load_model(cnn, \"cnn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7129b3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1843, -0.1843, -0.1843],\n",
       "         [ 0.1843,  0.1843,  0.1843],\n",
       "         [ 0.1843,  0.1843,  0.1843]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.conv_layers[0][0].weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e90b08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Inspecting convolutional layers...\n",
      "INFO: Next layer shape: torch.Size([1, 16, 28, 28]), equating to 12544 inputs\n",
      "INFO: Next layer shape: torch.Size([1, 32, 14, 14]), equating to 6272 inputs\n",
      "INFO: FC input size is 6272\n"
     ]
    }
   ],
   "source": [
    "cnn.inspect_conv_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec108810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Train Epoch:  1 [ 128/4000] Loss: 2.4665\n",
      "DEBUG: Train Epoch:  1 [ 768/4000] Loss: 1.4402\n",
      "DEBUG: Train Epoch:  1 [1408/4000] Loss: 1.1744\n",
      "DEBUG: Train Epoch:  1 [2048/4000] Loss: 1.0672\n",
      "DEBUG: Train Epoch:  1 [2688/4000] Loss: 0.8749\n",
      "DEBUG: Train Epoch:  1 [3328/4000] Loss: 0.5647\n",
      "DEBUG: Train Epoch:  1 [3968/4000] Loss: 0.4820\n",
      "DEBUG: Test set: Average loss: 0.8719, Accuracy: 579/800 (72.38%)\n",
      "DEBUG: Test set: Average loss: 0.8719, Accuracy: 579/800 (72.38%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max': 72.375, 'mean': np.float64(72.375), 'std': np.float64(0.0)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.cnn import CNNEvaluator\n",
    "\n",
    "\n",
    "cnn_evaluator = CNNEvaluator(cnn_params)\n",
    "cnn_evaluator.evaluate_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39cc38e",
   "metadata": {},
   "source": [
    "# Quantization Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae070f",
   "metadata": {},
   "source": [
    "## Techniques\n",
    "\n",
    "- Bitwidth quantization\n",
    "- BNN: Activation func (Using STE for gradients)\n",
    "- BNN_ReSTE: Activation func (Changing gradients: ReSTE)\n",
    "- TNN: Activation func (Differentiable? I'll need to implement it)\n",
    "- ... Find more?\n",
    "\n",
    "## How to integrate them\n",
    "\n",
    "Bitwidth quantization needs:\n",
    "- Quantization mode (Deterministic, Stochastic)\n",
    "- Per-layer: quantization level\n",
    "- Advances: Per perceptron quantization level. At least for the first layer\n",
    "\n",
    "Input bitwidth quantization. Closely tied to BNNs, as every other layer works with binary inputs\n",
    "- Per-input-neuron quantization level\n",
    "\n",
    "### BNN\n",
    "The idea is that every hidden layer only computes using binary (0/1, -1/+1) inputs & weights. Afaik bias isn't present. FC layer is simplified using popcount + ... operation. CNN in a similar mannet.\n",
    "- In the paper, they use hardtanh, ReLU. They also state that binarization itself is a form of non-linearity (used for hidden units). They use hardtanh even though they state that binarization itsef if a form of non-linearity. That's weird.\n",
    "\n",
    "Parameters:\n",
    "- None, I suppose.\n",
    "\n",
    "### BNN ReSTE\n",
    "Same as BNN, except for that:\n",
    "1. ReSTE is used instead of STE. ReSTE specifies a function to better estimate the quantized activation gradient.\n",
    "2. Gradients smaller than -1 and bigger than 1 are set to 0\n",
    "\n",
    "Parameters\n",
    "- o: Used for backprop. Modifies the approximated gradient.\n",
    "- t: Threshold\n",
    "- ...\n",
    "\n",
    "### TWN, Ternary weight networks\n",
    "Weights are one of: (-1,0,1). Paper focuses in CNNs. Nothing in mentioned of activation quantization. Typical pipeline is used: Conv -> BatchNorm -> Activation -> Maybe Pooling (every 2 conv layers?). Then FC layers.\n",
    "\n",
    "Notes:\n",
    "- The paper uses SGD.\n",
    "- We will likely combine it with neuron quantization.\n",
    "- FC & Conv do not have a bias.\n",
    "- I could apply something like ReSTE to this by using $y=\\frac{2arctan(10x^3)} {\\pi}$\n",
    "\n",
    "Parameters:\n",
    "- Threshold within which weight is set to 0?\n",
    "- ...\n",
    "\n",
    "### Idea: adaptive quantization -> static quantization\n",
    "During training use adaptive quantization, and for inference convert it to static quantization.\n",
    "- A potential problem: overflow, underflow?\n",
    "- ...\n",
    "\n",
    "### Some recap\n",
    "\n",
    "TWN and BNN do the same thing at its core: quantize weights. Extra things can be added like:\n",
    "- binary or ternary activation (activation returns either (-1/1) or (-1/0/1)), or ReLU + bitwidth quantization.\n",
    "- Input layer bitwidth quantization. (I should prefer per input quantization)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
