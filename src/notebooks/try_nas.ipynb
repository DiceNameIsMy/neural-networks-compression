{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa901b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(levelname)s: %(message)s\",\n",
    "    force=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.cifar10_dataset import CIFAR10Dataset\n",
    "\n",
    "\n",
    "X, y = CIFAR10Dataset.get_xy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31102229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nur/Projects/vut-ip1-nn-quantization/src/datasets/dataset.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n",
      "/home/nur/Projects/vut-ip1-nn-quantization/src/datasets/dataset.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y, dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "train, test = CIFAR10Dataset.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e515c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: Can't tell\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "def compare_architectures(scores_a, scores_b, alpha=0.05, architecture_names=None):\n",
    "    \"\"\"\n",
    "    Compare two lists of paired performance scores using Wilcoxon Signed-Rank Test.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    scores_a : array-like\n",
    "        Performance scores for architecture A (e.g., accuracy, F1-score)\n",
    "    scores_b : array-like\n",
    "        Performance scores for architecture B (must be same length as scores_a)\n",
    "    alpha : float, default=0.05\n",
    "        Significance level for the statistical test\n",
    "    architecture_names : tuple, default=None\n",
    "        Optional names for the architectures (name_a, name_b)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        One of: \"A is better\", \"B is better\", or \"Can't tell\"\n",
    "\n",
    "    Raises:\n",
    "    -------\n",
    "    ValueError\n",
    "        If input arrays have different lengths or other validation issues\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to numpy arrays for easier handling\n",
    "    scores_a = np.array(scores_a)\n",
    "    scores_b = np.array(scores_b)\n",
    "\n",
    "    # Validation\n",
    "    if len(scores_a) != len(scores_b):\n",
    "        raise ValueError(\"Both score lists must have the same length\")\n",
    "\n",
    "    if len(scores_a) < 3:\n",
    "        raise ValueError(\"Need at least 3 paired observations for meaningful results\")\n",
    "\n",
    "    # Set default names if not provided\n",
    "    if architecture_names is None:\n",
    "        name_a, name_b = \"A\", \"B\"\n",
    "    else:\n",
    "        name_a, name_b = architecture_names\n",
    "\n",
    "    try:\n",
    "        # Perform Wilcoxon Signed-Rank Test\n",
    "        # alternative='two-sided' tests if medians are different\n",
    "        statistic, p_value = wilcoxon(scores_a, scores_b, alternative=\"two-sided\")\n",
    "\n",
    "        # If not significant, we can't tell which is better\n",
    "        if p_value >= alpha:\n",
    "            return \"Can't tell\"\n",
    "\n",
    "        # If significant, determine which is better based on median difference\n",
    "        median_diff = np.median(scores_a - scores_b)\n",
    "\n",
    "        if median_diff > 0:\n",
    "            return f\"{name_a} is better\"\n",
    "        else:\n",
    "            return f\"{name_b} is better\"\n",
    "\n",
    "    except ValueError as e:\n",
    "        # Handle cases where all differences are zero or other issues\n",
    "        if \"zero\" in str(e).lower():\n",
    "            return \"Can't tell\"\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "\n",
    "# Example usage and demonstration\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Architecture A clearly better\n",
    "    scores_arch_a = [\n",
    "        75.80645161290323,\n",
    "        80.64516129032258,\n",
    "        48.38709677419355,\n",
    "        41.935483870967744,\n",
    "        85.48387096774194,\n",
    "        75.80645161290323,\n",
    "        79.03225806451613,\n",
    "        72.58064516129032,\n",
    "        72.58064516129032,\n",
    "        66.12903225806451,\n",
    "    ]\n",
    "    scores_arch_b = [\n",
    "        74.19354838709677,\n",
    "        67.74193548387096,\n",
    "        45.16129032258065,\n",
    "        38.70967741935484,\n",
    "        83.87096774193549,\n",
    "        70.96774193548387,\n",
    "        82.25806451612904,\n",
    "        75.80645161290323,\n",
    "        70.96774193548387,\n",
    "        79.03225806451613,\n",
    "    ]\n",
    "\n",
    "    result = compare_architectures(scores_arch_a, scores_arch_b)\n",
    "    print(f\"Example 1: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126678ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LeNet5 with NNParamsCompMode.NONE and Activation.NONE...\n",
      "Evaluating LeNet5 with NNParamsCompMode.NONE and Activation.RELU...\n",
      "Evaluating LeNet5 with NNParamsCompMode.NONE and Activation.BINARIZE...\n",
      "Evaluating LeNet5 with NNParamsCompMode.NONE and Activation.BINARIZE_RESTE...\n",
      "Evaluating LeNet5 with NNParamsCompMode.NONE and Activation.TERNARIZE...\n",
      "Evaluating LeNet5 with NNParamsCompMode.NBITS and Activation.NONE...\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "NBITS compression mode is not implemented for convolutional layers",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     14\u001b[39m model_params = get_LeNet5_params(\n\u001b[32m     15\u001b[39m     DatasetClass=MiniMNISTDataset,\n\u001b[32m     16\u001b[39m     conv_weight_qmode=compression,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     fc_activation=ActivationParams(activation),\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m evaluator = KFoldNNArchitectureEvaluator(model_params)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m stats = \u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m datapoints.append(\n\u001b[32m     25\u001b[39m     {\n\u001b[32m     26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33marchitecture\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mLeNet5\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     }\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vut-ip1-nn-quantization/src/models/eval.py:186\u001b[39m, in \u001b[36mKFoldNNArchitectureEvaluator.evaluate_accuracy\u001b[39m\u001b[34m(self, times)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28mself\u001b[39m.p.train.test_loader = data.DataLoader(\n\u001b[32m    180\u001b[39m     \u001b[38;5;28mself\u001b[39m.p.train.DatasetCls(X_test, y_test),\n\u001b[32m    181\u001b[39m     batch_size=\u001b[38;5;28mself\u001b[39m.p.train.batch_size,\n\u001b[32m    182\u001b[39m     shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    183\u001b[39m     num_workers=DATALOADERS_NUM_WORKERS,\n\u001b[32m    184\u001b[39m )\n\u001b[32m    185\u001b[39m evaluator = NNArchitectureEvaluator(\u001b[38;5;28mself\u001b[39m.p)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m stats = \u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m stats[\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[38;5;28mmax\u001b[39m(accuracies):\n\u001b[32m    189\u001b[39m     best_model = stats[\u001b[33m\"\u001b[39m\u001b[33mbest_model\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vut-ip1-nn-quantization/src/models/eval.py:29\u001b[39m, in \u001b[36mNNArchitectureEvaluator.evaluate_accuracy\u001b[39m\u001b[34m(self, times)\u001b[39m\n\u001b[32m     27\u001b[39m accuracies = []\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(times):\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.to(DEVICE)\n\u001b[32m     30\u001b[39m     model = \u001b[38;5;28mself\u001b[39m.train_model(model)\n\u001b[32m     31\u001b[39m     acc = \u001b[38;5;28mself\u001b[39m.test_model(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vut-ip1-nn-quantization/src/models/cnn.py:80\u001b[39m, in \u001b[36mCNNParams.get_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mCNN\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vut-ip1-nn-quantization/src/models/cnn.py:117\u001b[39m, in \u001b[36mCNN.__init__\u001b[39m\u001b[34m(self, p)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Inputs quantization\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.quantize_input = (\n\u001b[32m    114\u001b[39m     Quantize(QMode.DET, p.in_bitwidth) \u001b[38;5;28;01mif\u001b[39;00m p.in_bitwidth < \u001b[32m32\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nn.Identity()\n\u001b[32m    115\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28mself\u001b[39m.conv_layers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_conv_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m fc_in_height = \u001b[38;5;28mself\u001b[39m._get_fc_in_height(p, \u001b[38;5;28mself\u001b[39m.conv_layers)\n\u001b[32m    121\u001b[39m \u001b[38;5;28mself\u001b[39m.fc_layers = \u001b[38;5;28mself\u001b[39m.build_fc_layers(p, fc_in_height)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vut-ip1-nn-quantization/src/models/cnn.py:164\u001b[39m, in \u001b[36mCNN.build_conv_layers\u001b[39m\u001b[34m(cls, p)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_conv_layers\u001b[39m(\u001b[38;5;28mcls\u001b[39m, p: CNNParams) -> nn.ModuleList:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     ConvModule = \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_conv_module_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m     conv_layers = nn.ModuleList()\n\u001b[32m    167\u001b[39m     in_channels = p.conv.in_channels\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vut-ip1-nn-quantization/src/models/cnn.py:59\u001b[39m, in \u001b[36mConvParams.get_conv_module_cls\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Conv2dWrapper\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mcase\u001b[39;00m NNParamsCompMode.NBITS:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m     60\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNBITS compression mode is not implemented for convolutional layers\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m     )\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mcase\u001b[39;00m NNParamsCompMode.BINARY:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ternarize.Conv2dBinary\n",
      "\u001b[31mNotImplementedError\u001b[39m: NBITS compression mode is not implemented for convolutional layers"
     ]
    }
   ],
   "source": [
    "from src.datasets.mnist_dataset import MiniMNISTDataset\n",
    "from src.experiments.experiment1 import get_LeNet5_params\n",
    "from src.models.compression.enums import Activation, NNParamsCompMode\n",
    "from src.models.eval import KFoldNNArchitectureEvaluator\n",
    "from src.models.nn import ActivationParams\n",
    "\n",
    "\n",
    "datapoints = []\n",
    "\n",
    "for compression in NNParamsCompMode:\n",
    "    for activation in Activation:\n",
    "        print(f\"Evaluating LeNet5 with {compression} and {activation}...\")\n",
    "\n",
    "        model_params = get_LeNet5_params(\n",
    "            DatasetClass=MiniMNISTDataset,\n",
    "            conv_weight_qmode=compression,\n",
    "            conv_activation=ActivationParams(activation),\n",
    "            fc_weight_qmode=compression,\n",
    "            fc_activation=ActivationParams(activation),\n",
    "        )\n",
    "        evaluator = KFoldNNArchitectureEvaluator(model_params)\n",
    "\n",
    "        try:\n",
    "            stats = evaluator.evaluate_accuracy(1)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error evaluating {compression} with {activation}: {e}\")\n",
    "            continue\n",
    "\n",
    "        datapoints.append(\n",
    "            {\n",
    "                \"architecture\": \"LeNet5\",\n",
    "                \"dataset\": MiniMNISTDataset.__name__,\n",
    "                \"compression\": compression,\n",
    "                \"activation\": activation,\n",
    "                \"top-1\": stats[\"max\"],\n",
    "                \"mean\": stats[\"mean\"],\n",
    "                \"accuracies\": stats[\"accuracies\"],\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88669559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'architecture': 'LeNet5',\n",
       "  'dataset': 'MiniMNISTDataset',\n",
       "  'compression': <NNParamsCompMode.NONE: 'none'>,\n",
       "  'activation': <Activation.NONE: 'none'>,\n",
       "  'top-1': 93.375,\n",
       "  'mean': np.float64(92.525),\n",
       "  'accuracies': [93.375, 92.75, 92.375, 91.125, 93.0]},\n",
       " {'architecture': 'LeNet5',\n",
       "  'dataset': 'MiniMNISTDataset',\n",
       "  'compression': <NNParamsCompMode.NONE: 'none'>,\n",
       "  'activation': <Activation.RELU: 'relu'>,\n",
       "  'top-1': 96.625,\n",
       "  'mean': np.float64(96.1),\n",
       "  'accuracies': [96.625, 96.0, 95.875, 95.625, 96.375]},\n",
       " {'architecture': 'LeNet5',\n",
       "  'dataset': 'MiniMNISTDataset',\n",
       "  'compression': <NNParamsCompMode.NONE: 'none'>,\n",
       "  'activation': <Activation.BINARIZE: 'binary'>,\n",
       "  'top-1': 90.375,\n",
       "  'mean': np.float64(89.325),\n",
       "  'accuracies': [89.625, 90.0, 90.375, 88.375, 88.25]},\n",
       " {'architecture': 'LeNet5',\n",
       "  'dataset': 'MiniMNISTDataset',\n",
       "  'compression': <NNParamsCompMode.NONE: 'none'>,\n",
       "  'activation': <Activation.BINARIZE_RESTE: 'binary_ReSTE'>,\n",
       "  'top-1': 93.125,\n",
       "  'mean': np.float64(91.875),\n",
       "  'accuracies': [93.125, 89.0, 92.375, 92.75, 92.125]},\n",
       " {'architecture': 'LeNet5',\n",
       "  'dataset': 'MiniMNISTDataset',\n",
       "  'compression': <NNParamsCompMode.NONE: 'none'>,\n",
       "  'activation': <Activation.TERNARIZE: 'ternary'>,\n",
       "  'top-1': 78.0,\n",
       "  'mean': np.float64(70.85),\n",
       "  'accuracies': [78.0, 68.0, 73.625, 65.5, 69.125]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
